{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNpktkQwCblAVOa9iw0A5gn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### Import Libraries"],"metadata":{"id":"oKaCaBMH4lB6"}},{"cell_type":"code","source":["!pip install pysteps\n","!pip install kagglehub\n","from google.colab import drive\n","drive.mount('/content/drive/')\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import datasets, transforms, models\n","from torch.utils.data import DataLoader, random_split, ConcatDataset, Dataset, TensorDataset\n","from pysteps.utils import spectral\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from sklearn import metrics\n","import kagglehub"],"metadata":{"id":"4ygPOA6q4rIO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Move to GPU"],"metadata":{"id":"fchMnK8G44MR"}},{"cell_type":"code","source":["# Check if GPU is available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")"],"metadata":{"id":"zzRulTkn47_p"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Parameters"],"metadata":{"id":"89P8bEeU6rCR"}},{"cell_type":"code","source":["# To be modified or enhanced\n","batch_size = 32\n","num_epochs = 2\n","learning_rate = 0.001\n","rapsd_dim = 16*3\n","n_classes = 2"],"metadata":{"id":"Tv8D797m6ung"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Load Datasets"],"metadata":{"id":"PDC4mh0o5Cj5"}},{"cell_type":"markdown","source":["Datadream"],"metadata":{"id":"lGxyzufy5LuS"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","\n","synthetic_path = '/content/drive/MyDrive/SharedFolder/Project18/synthetic'\n","real_path = '/content/drive/MyDrive/SharedFolder/Project18/real'\n","\n","# Load datasets with ImageFolder\n","synthetic_datadream = datasets.ImageFolder(root=synthetic_path, transform=transform)\n","real_datadream = datasets.ImageFolder(root=real_path, transform=transform)"],"metadata":{"id":"esOtp2pG5UXU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Cifake"],"metadata":{"id":"npEvHRYs5N7O"}},{"cell_type":"code","source":["# Download CIFAKE dataset (CIFAR-10 subset and synthetic versions of each image)\n","path = kagglehub.dataset_download(\"birdy654/cifake-real-and-ai-generated-synthetic-images\")\n","print(\"Path to dataset files:\", path)\n","\n","cifake_images_path_test = path + \"/test\"\n","cifake_images_path_train = path + \"/train\"\n","\n","# Load datasets CIFAKE train and test\n","cifake_dataset_train = datasets.ImageFolder(root=cifake_images_path_train, transform=transform)\n","cifake_dataset_test = datasets.ImageFolder(root=cifake_images_path_test, transform=transform)"],"metadata":{"id":"UDXNHn9y5GCk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Functions"],"metadata":{"id":"cG5SSXw9659S"}},{"cell_type":"code","source":["# Function to prepare image for fft\n","def prepare_image_for_fft(image):\n","\n","    # Convert to numpy array\n","    image_np = image.cpu().numpy()\n","    return image_np"],"metadata":{"id":"7FtgS5Hk7fwD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def compute_rapsd_subset(subset):\n","    \"\"\"\n","    Computes RAPSD for a subset of images.\n","\n","    Parameters:\n","    - subset: List or dataset of (image, label) pairs.\n","\n","    Returns:\n","    - List of merged RAPSD features for each image.\n","    - List of frequency arrays for each image.\n","    \"\"\"\n","    rapsd_subset = []\n","    frequencies_subset = []\n","\n","    # For all images in subset\n","    for img, _ in subset:\n","        rapsd_features = []  # To store per-channel RAPSD for one image\n","        frequencies_list = []  # To store per-channel frequencies for one image\n","\n","        # Iterate over each of the three channels (RGB)\n","        for i in range(img.shape[0]):  # Assuming the image is 3xHxW (3 channels)\n","            # Prepare the image\n","            prepared_image = prepare_image_for_fft(img[i])\n","\n","            # Compute RAPSD\n","            rapsd, frequencies = spectral.rapsd(prepared_image, fft_method=np.fft, return_freq=True)\n","            rapsd_features.append(rapsd)\n","            frequencies_list.append(frequencies)\n","\n","        # Merge RAPSD features for all channels of one image\n","        merged_rapsd = np.concatenate(rapsd_features, axis=0)  # Combine RAPSD features for all channels\n","        merged_frequencies = np.array(frequencies_list[0])  # Use frequencies from the first channel (identical)\n","\n","        # Append per-image results\n","        rapsd_subset.append(merged_rapsd)\n","        frequencies_subset.append(merged_frequencies)\n","\n","    return rapsd_subset, frequencies_subset"],"metadata":{"id":"PoAKwPGz7ghw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def accuracy(target, pred):\n","  target = target.detach().cpu().numpy()\n","  pred = pred.detach().cpu().numpy()\n","  return metrics.accuracy_score(target, pred)"],"metadata":{"id":"oaD-7eDe7lz2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def compute_confusion_matrix(target, pred, normalize=None):\n","    return metrics.confusion_matrix(\n","        target.detach().cpu().numpy(),\n","        pred.detach().cpu().numpy(),\n","        normalize=normalize\n","    )"],"metadata":{"id":"JgQymZEm7qZK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Image Preprocessing"],"metadata":{"id":"FThsFBex7APh"}},{"cell_type":"code","source":["# Define transformations\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),  # Resize to 224x224\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize\n","])"],"metadata":{"id":"8wUOcy7f75IP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Statistical tests on RAPSD"],"metadata":{"id":"OiSmUmlp7E4p"}},{"cell_type":"markdown","source":["Student's t"],"metadata":{"id":"bvNJUiEY_Em7"}},{"cell_type":"code","source":[],"metadata":{"id":"5Te60ZUM_KR0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Cohen's d"],"metadata":{"id":"-XAsC2Bi_G_7"}},{"cell_type":"code","source":[],"metadata":{"id":"ZI8EOsZg_Jb-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Models"],"metadata":{"id":"qJb4O5ZR7L8J"}},{"cell_type":"markdown","source":[],"metadata":{"id":"EtaF5QH27OlN"}}]}